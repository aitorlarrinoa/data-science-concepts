{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d0d539",
   "metadata": {},
   "source": [
    "This notebook will be used with the aim of showing how a decision tree works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737b055",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937c5ed",
   "metadata": {},
   "source": [
    "# 2. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31150ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5fe8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ebc4a1",
   "metadata": {},
   "source": [
    "# 3. Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55e0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"../../data/credit_card_data/data_modified_binary_classification.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f6a77",
   "metadata": {},
   "source": [
    "# 4. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44121c29",
   "metadata": {},
   "source": [
    "# 5. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9956f7",
   "metadata": {},
   "source": [
    "We are going to make use of some credit card details data. The data is calculated in the notebook *00_transform_data_binary_classification.ipynb*. All needed information about the data is sotred there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2006098",
   "metadata": {},
   "source": [
    "We'll proceed the same way as with the logistic regression in order to give the reader consistency when reading these notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4983492",
   "metadata": {},
   "source": [
    "## 5.1. Load and transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2aa116",
   "metadata": {},
   "source": [
    "First of all we are going to load the both the data and the target variables making use of pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0833a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_owner</th>\n",
       "      <th>propert_owner</th>\n",
       "      <th>children</th>\n",
       "      <th>type_income</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>housing_type</th>\n",
       "      <th>employed_days</th>\n",
       "      <th>mobile_phone</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email_id</th>\n",
       "      <th>family_members</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  car_owner propert_owner  children           type_income         education  \\\n",
       "0         Y             Y         0             Pensioner  Higher education   \n",
       "1         Y             N         0  Commercial associate  Higher education   \n",
       "2         Y             N         0  Commercial associate  Higher education   \n",
       "3         Y             N         0  Commercial associate  Higher education   \n",
       "4         Y             N         0             Pensioner  Higher education   \n",
       "\n",
       "  marital_status       housing_type  employed_days  mobile_phone  work_phone  \\\n",
       "0        Married  House / apartment         365243             1           0   \n",
       "1        Married  House / apartment           -586             1           1   \n",
       "2        Married  House / apartment           -586             1           1   \n",
       "3        Married  House / apartment           -586             1           1   \n",
       "4        Married  House / apartment           -586             1           1   \n",
       "\n",
       "   phone  email_id  family_members  target  \n",
       "0      0         0               2       1  \n",
       "1      1         0               2       1  \n",
       "2      1         0               2       1  \n",
       "3      1         0               2       1  \n",
       "4      1         0               2       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(INPUT_PATH, sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea32d91",
   "metadata": {},
   "source": [
    "### Train / test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149b9e8",
   "metadata": {},
   "source": [
    "Before doing transformations in the data, we need to divide it into train and test. **Let's remember that all transformations must be fitted in the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15c5a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "132efc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf40ff6",
   "metadata": {},
   "source": [
    "We need to transform all categorical columns to numeric. First, let's detect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77cd4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = data.select_dtypes(include=\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41040341",
   "metadata": {},
   "source": [
    "We are going to use target encoder in order to transform the categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80420d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = ce.TargetEncoder(cols = categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc7abb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = target_encoder.fit_transform(X_train, y_train)\n",
    "X_test_processed = target_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85852565",
   "metadata": {},
   "source": [
    "This time, unlike when we trained our logistic regression, we do not need to scale variables. This is because of some properties:\n",
    "\n",
    "- Tree-based algorithms do not rely on distance metrics between data points. \n",
    "- Tree-based algorithms do not have coefficients in their variables in order to compare their impact.\n",
    "- Tree-based algorithms make binary decisions at each node based on a single feature and its threshold. The decision to split a node is based solely on how well it separates the data into different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f786d225",
   "metadata": {},
   "source": [
    "## 5.2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8978494",
   "metadata": {},
   "source": [
    "Let's initialize the model and train it then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb5f516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad41b48a",
   "metadata": {},
   "source": [
    "Once the model is trained, let's calculate predictions of the X_test_precessed data. Before calculating these predictions, we'll set the threshold to 0.1 as done in the logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e929939",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_processed)\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dcbd19",
   "metadata": {},
   "source": [
    "## 5.3. Metrics calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202878f",
   "metadata": {},
   "source": [
    "First, let's calculate some metrics and show them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced54206",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2eb10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The accuracy error value is: {accuracy}\")\n",
    "print(f\"The roc_auc value is: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c908b",
   "metadata": {},
   "source": [
    "Now we will plot both the confusion matrix and the roc curve:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705cd6d",
   "metadata": {},
   "source": [
    "**Confusion matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c359c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35928692",
   "metadata": {},
   "source": [
    "We can observe a very bad result for the confusion matrix. This is because of the threshold considered when calculating y_pred. We need to modify this threshold. We are considering the value 0.1 because is the default imbalance value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db46a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = np.where(y_pred_proba >= 0.1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc299d49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_new)\n",
    "print(f\"The accuracy error value is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_new, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72559628",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a475822",
   "metadata": {},
   "source": [
    "We can observe a better performance of the model now. However, let's remember that this is for logistic regression understanding purposes only. If we would like to find the best model, we should have to be more cautious and more precise when selecting the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4878be8",
   "metadata": {},
   "source": [
    "**ROC Curve:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebdaad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {round(roc_auc, 2)})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d9867",
   "metadata": {},
   "source": [
    "A 0.61 value in AUC gives us the clue that the model has some ability to discriminate between positive and negative instances. It is not a very sharp model, but the model's discriminatory power is slightly better than random guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118158a2",
   "metadata": {},
   "source": [
    "## 5.4. Interpretion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c39b2f",
   "metadata": {},
   "source": [
    "Let's attend at the coefficient values a moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'Feature': list(X_train.columns) + [\"intercept\"], \n",
    "                        'Coefficient': list(model.coef_[0]) + [model.intercept_[0]]})\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1f504",
   "metadata": {},
   "source": [
    "The strongest coefs are the type_income and family_members variables. This makes a lot of sense considering that our dataset is about credit card application approved or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e92a8",
   "metadata": {},
   "source": [
    "Results show that we are in front of a not so good model but not so bad model also. Maybe a consideration of hyperparameter tunning or a tree based algorithm would give us the boost in order to get better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
